{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) Spark Dataframe Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "\n",
    "pandas_dataframe = pd.DataFrame(\n",
    "    {\n",
    "        \"n\": np.random.randn(20),\n",
    "        \"group\": np.random.choice(list(\"xyz\"), 20),\n",
    "        \"abool\": np.random.choice([True, False], 20),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the pandas dataframe to a spark dataframe. From this point forward, do all of your work with the spark dataframe, not the pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "|  0.5323378882945463|    y|false|\n",
      "|  1.3501878997225267|    z|false|\n",
      "|  0.8612113741693206|    x|false|\n",
      "|  1.4786857374358966|    z| true|\n",
      "| -1.0453771305385342|    y| true|\n",
      "| -0.7889890249515489|    x|false|\n",
      "|  -1.261605945319069|    y|false|\n",
      "|  0.5628467852810314|    y| true|\n",
      "|-0.24332625188556253|    y| true|\n",
      "|  0.9137407048596775|    y|false|\n",
      "| 0.31735092273633597|    x|false|\n",
      "| 0.12730328020698067|    z|false|\n",
      "|  2.1503829673811126|    y| true|\n",
      "|  0.6062886568962988|    x|false|\n",
      "|-0.02677164998644...|    x| true|\n",
      "+--------------------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the first 3 rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the first 7 rows of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "|  0.5323378882945463|    y|false|\n",
      "|  1.3501878997225267|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View a summary of the data using .describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----+\n",
      "|summary|                  n|group|\n",
      "+-------+-------------------+-----+\n",
      "|  count|                 20|   20|\n",
      "|   mean|0.36640264498852165| null|\n",
      "| stddev| 0.8905322898155364| null|\n",
      "|    min| -1.261605945319069|    x|\n",
      "|    max| 2.1503829673811126|    z|\n",
      "+-------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use .select to create a new dataframe with just the n and abool columns. View the first 5 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                   n|abool|\n",
      "+--------------------+-----+\n",
      "|  -0.712390662050588|false|\n",
      "|   0.753766378659703|false|\n",
      "|-0.04450307833805...|false|\n",
      "| 0.45181233874578974|false|\n",
      "|  1.3451017084510097|false|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('n','abool').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use .select to create a new dataframe with just the group and abool columns. View the first 5 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|group|abool|\n",
      "+-----+-----+\n",
      "|    z|false|\n",
      "|    x|false|\n",
      "|    z|false|\n",
      "|    y|false|\n",
      "|    z|false|\n",
      "+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('group','abool').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use .select to create a new dataframe with the group column and the abool column renamed to a_boolean_value. Show the first 3 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+\n",
      "|group|boolean_value|\n",
      "+-----+-------------+\n",
      "|    z|        false|\n",
      "|    x|        false|\n",
      "|    z|        false|\n",
      "+-----+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('group',df.abool.alias('boolean_value')).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use .select to create a new dataframe with the group column and the n column renamed to a_numeric_value. Show the first 6 rows of this dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|group|     a_numeric_value|\n",
      "+-----+--------------------+\n",
      "|    z|  -0.712390662050588|\n",
      "|    x|   0.753766378659703|\n",
      "|    z|-0.04450307833805...|\n",
      "|    y| 0.45181233874578974|\n",
      "|    z|  1.3451017084510097|\n",
      "|    y|  0.5323378882945463|\n",
      "+-----+--------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('group',df.n.alias('a_numeric_value')).show(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) Column Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the starter code above to re-create a spark dataframe. Store the spark dataframe in a varaible named df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(pandas_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use .select to add 4 to the n column. Show the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|           (n + 4)|\n",
      "+------------------+\n",
      "|3.2876093379494122|\n",
      "| 4.753766378659703|\n",
      "|3.9554969216619464|\n",
      "|  4.45181233874579|\n",
      "|5.3451017084510095|\n",
      "| 4.532337888294546|\n",
      "| 5.350187899722527|\n",
      "|  4.86121137416932|\n",
      "| 5.478685737435897|\n",
      "| 2.954622869461466|\n",
      "|3.2110109750484512|\n",
      "| 2.738394054680931|\n",
      "| 4.562846785281032|\n",
      "|3.7566737481144377|\n",
      "| 4.913740704859677|\n",
      "| 4.317350922736336|\n",
      "| 4.127303280206981|\n",
      "| 6.150382967381113|\n",
      "| 4.606288656896298|\n",
      "|3.9732283500135592|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.n + 4).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtract 5 from the n column and view the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|            (n - 5)|\n",
      "+-------------------+\n",
      "| -5.712390662050588|\n",
      "| -4.246233621340297|\n",
      "| -5.044503078338053|\n",
      "|  -4.54818766125421|\n",
      "|-3.6548982915489905|\n",
      "| -4.467662111705454|\n",
      "|-3.6498121002774733|\n",
      "|  -4.13878862583068|\n",
      "| -3.521314262564103|\n",
      "| -6.045377130538534|\n",
      "| -5.788989024951549|\n",
      "| -6.261605945319069|\n",
      "| -4.437153214718968|\n",
      "| -5.243326251885563|\n",
      "| -4.086259295140323|\n",
      "| -4.682649077263664|\n",
      "| -4.872696719793019|\n",
      "|-2.8496170326188874|\n",
      "| -4.393711343103702|\n",
      "| -5.026771649986441|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.n - 5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiply the n column by 2. View the results along with the original numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|             (n * 2)|                   n|\n",
      "+--------------------+--------------------+\n",
      "|  -1.424781324101176|  -0.712390662050588|\n",
      "|   1.507532757319406|   0.753766378659703|\n",
      "|-0.08900615667610691|-0.04450307833805...|\n",
      "|  0.9036246774915795| 0.45181233874578974|\n",
      "|  2.6902034169020195|  1.3451017084510097|\n",
      "|  1.0646757765890926|  0.5323378882945463|\n",
      "|  2.7003757994450535|  1.3501878997225267|\n",
      "|  1.7224227483386412|  0.8612113741693206|\n",
      "|   2.957371474871793|  1.4786857374358966|\n",
      "| -2.0907542610770684| -1.0453771305385342|\n",
      "| -1.5779780499030978| -0.7889890249515489|\n",
      "|  -2.523211890638138|  -1.261605945319069|\n",
      "|  1.1256935705620628|  0.5628467852810314|\n",
      "|-0.48665250377112507|-0.24332625188556253|\n",
      "|   1.827481409719355|  0.9137407048596775|\n",
      "|  0.6347018454726719| 0.31735092273633597|\n",
      "| 0.25460656041396135| 0.12730328020698067|\n",
      "|   4.300765934762225|  2.1503829673811126|\n",
      "|  1.2125773137925977|  0.6062886568962988|\n",
      "|-0.05354329997288145|-0.02677164998644...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.n * 2, df.n).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a new column named n2 that is the n value multiplied by -1. Show the first 4 rows of your dataframe. You should see the original n value as well as n2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                   n|                  n2|\n",
      "+--------------------+--------------------+\n",
      "|  -0.712390662050588|   0.712390662050588|\n",
      "|   0.753766378659703|  -0.753766378659703|\n",
      "|-0.04450307833805...|0.044503078338053455|\n",
      "| 0.45181233874578974|-0.45181233874578974|\n",
      "+--------------------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = df.select(df.n, (df.n * -1).alias('n2'))\n",
    "n.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a new column named n3 that is the n value squared. Show the first 5 rows of your dataframe. You should see both n, n2, and n3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                   n|                  n2|                  n3|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|  -0.712390662050588|   0.712390662050588|   0.507500455376875|\n",
      "|   0.753766378659703|  -0.753766378659703|  0.5681637535977627|\n",
      "|-0.04450307833805...|0.044503078338053455|0.001980523981562...|\n",
      "| 0.45181233874578974|-0.45181233874578974| 0.20413438944294027|\n",
      "|  1.3451017084510097| -1.3451017084510097|  1.8092986060778251|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n.select('*', (n.n ** 2).alias('n3')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens when you run the code below?\n",
    "\n",
    "df.group + df.abool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A column object is created that is defined as df.group + df.abool. We do not see an error here becuase this is just a column transformation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens when you run the code below? What is the difference between this and the previous code sample?\n",
    "\n",
    "df.select(df.group + df.abool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An error message is produced when we try to select this because the columns are different data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.) Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the starter code above to re-create a spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(pandas_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn your dataframe into a table that can be queried with spark SQL. Name the table my_df. Answer the rest of the questions in this section with a spark sql query (spark.sql) against my_df. After each step, view the first 7 records from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df = spark.sql('''SELECT * FROM df''')\n",
    "type(my_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query that shows all of the columns from your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "|  0.5323378882945463|    y|false|\n",
      "|  1.3501878997225267|    z|false|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_df.show(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query that shows just the n and abool columns from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                   n|abool|\n",
      "+--------------------+-----+\n",
      "|  -0.712390662050588|false|\n",
      "|   0.753766378659703|false|\n",
      "|-0.04450307833805...|false|\n",
      "| 0.45181233874578974|false|\n",
      "|  1.3451017084510097|false|\n",
      "|  0.5323378882945463|false|\n",
      "|  1.3501878997225267|false|\n",
      "+--------------------+-----+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_df.select('n','abool').show(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query that shows just the n and group columns. Rename the group column to g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|                   n|  g|\n",
      "+--------------------+---+\n",
      "|  -0.712390662050588|  z|\n",
      "|   0.753766378659703|  x|\n",
      "|-0.04450307833805...|  z|\n",
      "| 0.45181233874578974|  y|\n",
      "|  1.3451017084510097|  z|\n",
      "|  0.5323378882945463|  y|\n",
      "|  1.3501878997225267|  z|\n",
      "+--------------------+---+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_df.select('n',df.group.alias('g')).show(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a query that selects n, and creates two new columns: n2, the original n values halved, and n3: the original n values minus 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                   n|                  n2|                  n3|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|  -0.712390662050588|  -0.356195331025294|  -1.712390662050588|\n",
      "|   0.753766378659703|  0.3768831893298515|-0.24623362134029703|\n",
      "|-0.04450307833805...|-0.02225153916902...| -1.0445030783380536|\n",
      "| 0.45181233874578974| 0.22590616937289487| -0.5481876612542103|\n",
      "|  1.3451017084510097|  0.6725508542255049| 0.34510170845100974|\n",
      "|  0.5323378882945463| 0.26616894414727316| -0.4676621117054537|\n",
      "|  1.3501878997225267|  0.6750939498612634| 0.35018789972252673|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n2 = (my_df.n / 2).alias('n2')\n",
    "n3 = (my_df.n - 1).alias('n3')\n",
    "my_df.select('n',n2,n3).show(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if you make a SQL syntax error in your query?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Py4JJavaError error is printed. It explains there is an issue with the sql code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.) Type Casting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the starter code above to re-create a spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "|  0.5323378882945463|    y|false|\n",
      "|  1.3501878997225267|    z|false|\n",
      "|  0.8612113741693206|    x|false|\n",
      "|  1.4786857374358966|    z| true|\n",
      "| -1.0453771305385342|    y| true|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use .printSchema to view the datatypes in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- n: double (nullable = true)\n",
      " |-- group: string (nullable = true)\n",
      " |-- abool: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use .dtypes to view the datatypes in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('n', 'double'), ('group', 'string'), ('abool', 'boolean')]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the difference between the two code samples below?\n",
    "\n",
    "df.abool.cast('int')\n",
    "\n",
    "\n",
    "df.select(df.abool.cast('int')).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line of code casts the abool column with the data type integer. This is a simple transformation. The second line shows the new transformed data. This is an action. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use .select and .cast to convert the abool column to an integer type. View the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|abool|\n",
      "+-----+\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "|    0|\n",
      "|    1|\n",
      "|    1|\n",
      "+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.abool.cast('int')).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the group column to an integer data type and view the results. What happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns null values because the group column contains non numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|group|\n",
      "+-----+\n",
      "| null|\n",
      "| null|\n",
      "| null|\n",
      "+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.group.cast('int')).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the n column to a integer data type and view the results. What happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The n column is converted to data type integer. The values are rounded down to the nearest whole number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|  n|\n",
      "+---+\n",
      "|  0|\n",
      "|  0|\n",
      "|  0|\n",
      "|  0|\n",
      "|  1|\n",
      "+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.n.cast('int')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the abool column to a string data type and view the results. What happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The abool column is converted to a string without any issues becuase the booleans were already expressed in alpha characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|abool|\n",
      "+-----+\n",
      "|false|\n",
      "|false|\n",
      "|false|\n",
      "+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.abool.cast('string')).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.) Built-in Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the starter code above to re-create a spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|                   n|group|abool|\n",
      "+--------------------+-----+-----+\n",
      "|  -0.712390662050588|    z|false|\n",
      "|   0.753766378659703|    x|false|\n",
      "|-0.04450307833805...|    z|false|\n",
      "| 0.45181233874578974|    y|false|\n",
      "|  1.3451017084510097|    z|false|\n",
      "|  0.5323378882945463|    y|false|\n",
      "|  1.3501878997225267|    z|false|\n",
      "|  0.8612113741693206|    x|false|\n",
      "|  1.4786857374358966|    z| true|\n",
      "| -1.0453771305385342|    y| true|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(pandas_dataframe)\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary functions from pyspark.sql.functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import min, max, mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the highest n value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the lowest n value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the average n value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use concat to change the group column to say, e.g. \"Group: x\" or \"Group: y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use concat to combine the n and group columns to produce results that look like this: \"x: -1.432\" or \"z: 2.352"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
