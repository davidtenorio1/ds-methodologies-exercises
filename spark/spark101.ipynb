{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) Create a spark data frame that contains your favorite programming languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The name of the column should be language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "| languages|\n",
      "+----------+\n",
      "|    Python|\n",
      "|      Java|\n",
      "|       SQL|\n",
      "|       C++|\n",
      "|      Ruby|\n",
      "|   Haskell|\n",
      "|JavaScript|\n",
      "|        C#|\n",
      "|     Scala|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "languages = pd.DataFrame({'languages' : ['Python', 'Java', 'SQL', 'C++', 'Ruby', 'Haskell', 'JavaScript', 'C#', 'Scala']})\n",
    "\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "df = spark.createDataFrame(languages)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- View the schema of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- languages: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Output the shape of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 1)\n"
     ]
    }
   ],
   "source": [
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|languages|\n",
      "+---------+\n",
      "|   Python|\n",
      "|     Java|\n",
      "|      SQL|\n",
      "|      C++|\n",
      "|     Ruby|\n",
      "+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) Load the mpg dataset as a spark dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create 1 column of output that contains a message like the one below:\n",
    "\n",
    "    <mark>The 1999 audi a4 has a 4 cylinder engine.</mark>\n",
    "\n",
    "    For each vehicle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydataset import data\n",
    "mpg = data('mpg')\n",
    "df = spark.createDataFrame(mpg)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------+\n",
      "|sentence                                                     |\n",
      "+-------------------------------------------------------------+\n",
      "|The 1999 audi a4 has a 4cylinder engine.                     |\n",
      "|The 1999 audi a4 has a 4cylinder engine.                     |\n",
      "|The 2008 audi a4 has a 4cylinder engine.                     |\n",
      "|The 2008 audi a4 has a 4cylinder engine.                     |\n",
      "|The 1999 audi a4 has a 6cylinder engine.                     |\n",
      "|The 1999 audi a4 has a 6cylinder engine.                     |\n",
      "|The 2008 audi a4 has a 6cylinder engine.                     |\n",
      "|The 1999 audi a4 quattro has a 4cylinder engine.             |\n",
      "|The 1999 audi a4 quattro has a 4cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a 4cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a 4cylinder engine.             |\n",
      "|The 1999 audi a4 quattro has a 6cylinder engine.             |\n",
      "|The 1999 audi a4 quattro has a 6cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a 6cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a 6cylinder engine.             |\n",
      "|The 1999 audi a6 quattro has a 6cylinder engine.             |\n",
      "|The 2008 audi a6 quattro has a 6cylinder engine.             |\n",
      "|The 2008 audi a6 quattro has a 8cylinder engine.             |\n",
      "|The 2008 chevrolet c1500 suburban 2wd has a 8cylinder engine.|\n",
      "|The 2008 chevrolet c1500 suburban 2wd has a 8cylinder engine.|\n",
      "+-------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.concat(F.lit('The '), df.year, \n",
    "                F.lit(' '),df.manufacturer,\n",
    "                F.lit(' ') ,df.model,F.lit(' has a '), df.cyl,\n",
    "                F.lit('cylinder engine.'))\n",
    "                .alias('sentence')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transform the trans column so that it only contains either manual or auto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|trans_new|\n",
      "+---------+\n",
      "|     auto|\n",
      "|   manual|\n",
      "|   manual|\n",
      "|     auto|\n",
      "|     auto|\n",
      "|   manual|\n",
      "|     auto|\n",
      "|   manual|\n",
      "|     auto|\n",
      "|   manual|\n",
      "|     auto|\n",
      "|     auto|\n",
      "|   manual|\n",
      "|     auto|\n",
      "|   manual|\n",
      "|     auto|\n",
      "|     auto|\n",
      "|     auto|\n",
      "|     auto|\n",
      "|     auto|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.regexp_extract('trans', r'^([a-z]+)', 1).alias('trans_new')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.) Load the tips database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = data('tips')\n",
    "df = spark.createDataFrame(df)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What percentage of observations are smokers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38114754098360654"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.filter(df.smoker == 'Yes').count()) / df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a column that contains the tip percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|     tip_percentage|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|0.16658733936220846|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1397804054054054|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|0.14680764538430255|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|0.18623962040332148|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|0.22805017103762829|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|0.11607142857142858|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|0.13031914893617022|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2| 0.2185385656292287|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2| 0.1665043816942551|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|0.14180374361883155|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|0.10181582360570687|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|0.16277807921866522|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|0.20364126770060686|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|0.18164967562557924|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3| 0.1616650532429816|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|0.22774708410067526|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|0.20624631703005306|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|0.16222760290556903|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('*',(df.tip/df.total_bill).alias('tip_percentage')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------------------+\n",
      "|   sex|smoker|          avg(tip)|\n",
      "+------+------+------------------+\n",
      "|  Male|    No|3.1134020618556697|\n",
      "|  Male|   Yes|3.0511666666666666|\n",
      "|Female|    No| 2.773518518518518|\n",
      "|Female|   Yes|2.9315151515151516|\n",
      "+------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('sex','smoker').mean('tip').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.) Use the seattle weather dataset referenced in the lesson to answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|               date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01 00:00:00|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02 00:00:00|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03 00:00:00|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04 00:00:00|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05 00:00:00|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "+-------------------+-------------+--------+--------+----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vega_datasets import data\n",
    "weather = data.seattle_weather()\n",
    "df = spark.createDataFrame(weather)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert the temperatures to farenheight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+------------------+------------------+----+-------+\n",
      "|               date|precipitation|          temp_max|          temp_min|wind|weather|\n",
      "+-------------------+-------------+------------------+------------------+----+-------+\n",
      "|2012-01-01 00:00:00|          0.0|             55.04|              41.0| 4.7|drizzle|\n",
      "|2012-01-02 00:00:00|         10.9|             51.08|             37.04| 4.5|   rain|\n",
      "|2012-01-03 00:00:00|          0.8|             53.06|             44.96| 2.3|   rain|\n",
      "|2012-01-04 00:00:00|         20.3|             53.96|             42.08| 4.7|   rain|\n",
      "|2012-01-05 00:00:00|          1.3|             48.02|             37.04| 6.1|   rain|\n",
      "|2012-01-06 00:00:00|          2.5|             39.92|             35.96| 2.2|   rain|\n",
      "|2012-01-07 00:00:00|          0.0|             44.96|             37.04| 2.3|   rain|\n",
      "|2012-01-08 00:00:00|          0.0|              50.0|             37.04| 2.0|    sun|\n",
      "|2012-01-09 00:00:00|          4.3|             48.92|              41.0| 3.4|   rain|\n",
      "|2012-01-10 00:00:00|          1.0|42.980000000000004|             33.08| 3.4|   rain|\n",
      "|2012-01-11 00:00:00|          0.0|42.980000000000004|             30.02| 5.1|    sun|\n",
      "|2012-01-12 00:00:00|          0.0|42.980000000000004|             28.94| 1.9|    sun|\n",
      "|2012-01-13 00:00:00|          0.0|              41.0|             26.96| 1.3|    sun|\n",
      "|2012-01-14 00:00:00|          4.1|             39.92|             33.08| 5.3|   snow|\n",
      "|2012-01-15 00:00:00|          5.3|             33.98|26.060000000000002| 3.2|   snow|\n",
      "|2012-01-16 00:00:00|          2.5|             35.06|             26.96| 5.0|   snow|\n",
      "|2012-01-17 00:00:00|          8.1|             37.94|              32.0| 5.6|   snow|\n",
      "|2012-01-18 00:00:00|         19.8|              32.0|             26.96| 5.0|   snow|\n",
      "|2012-01-19 00:00:00|         15.2|             30.02|             26.96| 1.6|   snow|\n",
      "|2012-01-20 00:00:00|         13.5|             44.96|             30.02| 2.3|   snow|\n",
      "+-------------------+-------------+------------------+------------------+----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('temp_max', df.temp_max * 9 / 5 + 32).withColumn('temp_min', df.temp_min * 9 / 5 + 32).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which month has the most rain, on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'month' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-52955a28a386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precipitation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'avg_monthly_rain'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'month' is not defined"
     ]
    }
   ],
   "source": [
    "df.withColumn('month', month('date')).groupBy('month').agg(mean('precipitation').alias('avg_monthly_rain')).sort('month').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Which year was the windiest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the most frequent type of weather in January?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What is the average high and low tempurature on sunny days in July in 2013 and 2014?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What percentage of days were rainy in q3 of 2015?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
